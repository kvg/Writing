\chapter{Detection and classification}
\label{ch:methods}

\newthought{We now present a novel graphical method} for detecting and classifiying \textit{de novo} variants.  We shall present some brief foundational background on \textit{de novo} assembly and graphical models, concepts upon which the variant caller is built.  The simulation framework and dataset we described in Chapter \ref{ch:simulation} will be used to establish the method's accuracy.

Reference-based analyses benefit from being reasonably intuitive, as the underlying genome is linear and there are many visualization tools that can facilitate the user's understanding of the underlying data\cite{Li:2009p181,Bao:2009ie,Robinson:2011gy,Milne:2013gf,Thorvaldsdottir:2013iw}.  In contrast, graph data structures are far less intuitive and lack dedicated visualization tools in the genomics space.  In this chapter, we will also present images from our purpose-built graph visualization software for the purposes of guiding the reader's intuition regarding graphical variant motifs and the operation of the calling algorithms.

\section{\textit{De novo} assembly}

\textit{De novo} assembly refers to the process wherein a sampled genome is reconstructed from sequencing data without guidance from an existing genome.  Sequenced deeply enough, a set of reads from a single sample will contain overlaps that can be used to infer the sequence of contiguous segments of the genome into so-called \textbf{contigs}.  If the reads are long enough to span repetitive regions in the genome, these contigs could be as long as the chromosome itself.  Otherwise, separate contigs can be joined together into \textbf{scaffolds} (contigs plus gaps) using paired-end reads, long reads, information from linkage analysis, Hi-C data\cite{Burton:2013dj}, or other methods.

The quality of the reconstruction can vary considerably depending on how the assembly is performed.  Typically, constructing a complete and high-quality reference sequence (one with few errors and few gaps in the linear sequence of each assembled chromosome) is a big first step to studying the genome of an organism, done at great expense and labor over a period of several years.  In 2002, after several years of work, Gardner \textit{et al.} published the sequence of the 3D7 \textit{P. falciparum} parasite clone.  By using a whole chromosome shotgun strategy with accurate and long (several hundred bp) first-generation sequencing reads (Sanger), each chromosome was fully resolved with very few gaps in the sequence and no unplaced contigs\cite{Gardner:2002p1564}.

Today, the same sample can be assembled in a matter of days rather than years using high-throughput second-generation sequencing.  Short reads ($76-100$ bp) from second-generation sequencers (Illumina) can be produced cheaply and in abundant quantities, and similar read overlap considerations can be used to generate assemblies.  However, these reads tend to be much more error prone, and the shorter read length fails to span many repetitive regions of the genome.  The result is a much cheaper, but far more fragmented assembly than the reference assembly.  Table \ref{tbl:asmcompare} compares the assembly statistics of the reference genome versus a reconstruction of the same sample from Illumina data taken from our cross dataset (PG0051-C) using the McCortex assembly software\cite{Turner:2015ve}.  While the parasite genome is known to have $16$ chromosomes (which the reference recapitulates), the Illumina assembly broken into over $50,000$ pieces with an N50\footnote{\textbf{N50}: the length for which the set of all contigs that length or greater represents half the total lengths of all contigs.} of a mere $1,280$ bp.

\begin{table}[]
\centering
\caption{Comparison of assembly statistics of the finished 3D7 reference genome and a reconstruction of the same sample from $76$-bp Illumina data.}
\label{tbl:asmcompare}
\begin{tabular}{@{}lllllll@{}}
\toprule
          & contigs & min length & max length & mean length & N50     & total sequence \\ \midrule
3D7       & 16      & 5967       & 3291936    & 1458302     & 1687656 & 23332831       \\
PG0051-C  & 51425   & 47         & 27520      & 478         & 1280    & 24602599       \\ \bottomrule
\end{tabular}
\end{table}

It is perhaps surprising then to discover the central argument of this dissertation is on the value of \textit{de novo} assembly of short reads for \textit{de novo} mutation discovery.  After all, a poor-quality Illumina assembly - as evidenced by the numerous short contigs - would seem to be very limiting, even if it could theoretically reconstruct pieces of the genome that cannot be recovered from a reference-based analysis.  However, for the work that we describe in this chapter, the value is not in the contig reconstructions, but in the underlying data structure from which the contigs are produced: the "de Bruijn graph".

The de Bruijn graph is a data structure that encodes read overlaps such that a walk through the vertices with unambiguous connections yields contiguous sequence in the genome.  In real data, those walks may end prematurely due to errors or homology, yielding junctions that cannot be confidently navigated.  Typically, assembly algorithms will be conservative in the contigs they emit from this data, choosing to terminate the walk at the junction rather than risk going forward and emitting sequence that does not actually appear in the genome.  However, with an additional set of metadata and a reasonable assumption, we can traverse the barrier.  In trio data, it is easy to detect a so-called novel kmer: a kmer occuring in the child but absent in the parents.  By annotating the graph with this information, we can see stretches of novel kmers.  Figure \ref{fig:graphwithextras} shows a portion of such an annotated graph.  Ignoring the annotations, a traversal that starts at vertex $D$ would yield a short contig: $C \rightarrow D \rightarrow E$.  However, if we assume the novel kmers link together, we can extend our traversal to yield $C \rightarrow D \rightarrow E \rightarrow F \rightarrow G \rightarrow H$.  These novel kmers are the hallmark of \textit{de novo} variation, and by utilizing these annotations, we can navigate parts of the graph that are otherwise unnavigable, surpassing what conservative contigs can give us and providing tremendous sensitivity and specificity to DNMs.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.8\textwidth]{graphwithextras}
  \caption{Graph with novel kmer annotations in red.}
  \label{fig:graphwithextras}
\end{figure}

\subsection{Definitions}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{examplegraph}
  \caption{An example directed graph with six vertices.}
  \label{fig:examplegraph}
\end{figure}

Let us establish some definitions.  We denote a \textbf{graph} as $G = \{\mathcal{V}, \mathcal{E}\}$ where $\mathcal{V}$ represents a unique set of \textbf{vertices}, and $\mathcal{E}$ a set of \textbf{edges}\cite{Koller:2009ty}.  We shall assume the set of vertices $\mathcal{V} = V_1, V_2, ..., V_n$.  A pair of vertices may be connected by an edge.  For the purposes of this dissertation, we shall require that all edges are \textbf{directed} (though for some applications outside this work, it is also possible for edges to be \textbf{undirected}).  Written as $V_i \rightarrow V_j$ (or equivalently $V_i \leftarrow V_j$ and $V_j \rightarrow V_i$), directed edges restrict graph traversal in one direction (thus enforcing a traversal order when reconstructing a region of the genome).  A vertex may have a number of incoming (outgoing) edges, the precise count being referred to as a vertex's \textbf{in- (out-) degree}.  We shall also refer to any vertex with an in-degree or out-degree greater than $1$ as a \textbf{junction}.

A \textbf{path} is a sequence of adjacent vertices that respects these edge relationships, i.e. $V_i, ..., V_k$ such that for every $j = i, ..., k$, we have $V_j \rightarrow V_{j+1}$.  In Figure \ref{fig:examplegraph}, the vertex sequence $A, B, C, F$ forms a path.  Similarly, a \textbf{trail} denotes a sequence of adjacent vertices, but does not respect the directionality of the edges.  In Figure \ref{fig:examplegraph}, the sequence $F, E, D, A$ forms a trail.  Edges can optionally carry \textbf{weight}, indicating an arbitrary cost for traversing from one vertex to another via particular edges.  Unless otherwise specified, we shall assume the edge weight is always $1$ (however, see Chapter \ref{ch:discussion} for a discussion on circumstances where weights might be a fruitful parameter in a graphical model of sequence assembly).

A \textbf{multi-color graph} is a useful extension for multi-sample scenarios.  Each edge carries additional metadata used to denote sample identity (e.g. each sample is assigned a unique "color").  All kmers in all samples are added to the graph, and following the edges with the same color yields the genome of that sample.  Many kmers will not be accessible when traversing paths or trails in one color versus another.  These motifs are the hallmark of most variation in a graphical setting.

Often in this dissertation, we will perform operations on a limited graph region wherein we process only vertices of interest and all edges present between them in the original graph.  This is referred to as an \textbf{induced subgraph} (which is \textit{not} technically synonymous with a subgraph, but for simplicity in this work, we will often drop the "induced" qualifier).  Let $\mathbf{V} \subset \mathcal{V}$.  The \textbf{subgraph} $G[\mathbf{V}] = \{\mathbf{V}, \mathcal{E'}\}$ where $\mathcal{E'}$ are all the edges $V_i \rightleftharpoons V_j \in \mathcal{E}$ such that $V_i, V_j \in \mathbf{V}$.

A \textbf{de Bruijn} graph represents fixed length symbols (vertices) and their overlaps (edges), with the added restriction that each symbol may only appear once in the graph\cite{Bruijn:1946va}.  Applied to assembly, each symbol is taken to be a genomic sequence of length $k$ (or \textbf{kmer}), with edges connecting vertices overlapping by $k-1$ bases\footnote{According to the original mathematical definition, a de Bruijn graph should represent \textit{every} possible symbol of length $k$, which makes the assembly formulation a subgraph rather than a graph.  However, none of the relevant literature refers to assembly graphs in this manner, so we shall carry on abusing the term.}.

To construct the initial graph, each sequenced read is broken up into $l-k+1$ kmers (where $l$ is the read length) and added to the graph as vertices, with edges being placed between adjacent kmers.  Overlapping reads should share kmers, and the adjacency information stored in the graph can be updated accordingly.  Thus processing one read at a time in this manner will yield a graph of overlaps for the entire dataset.

We rely on the Cortex assembly software for construction of the graph.  Cortex represents the graph on disk as fixed-width records (herein referred to as \textbf{CortexRecords}) consisting of a \textbf{CortexKmer} (defined as a odd-length kmer or its reverse complement, whichever is alphanumerically lower; two CortexKmers constructed from a forward sequence and the reverse complement of that sequence evaluate to the same object), coverage in each color, and a list of incoming and outgoing edges.  The edge lists utilize a minimalist description.  For incoming edges, only the first base of the preceeding kmer is stored; the rest of the kmer is assumed to be the $0$ to $k-1$ substring of the current kmer.  Likewise, for outgoing edges, the subsequent kmer is assumed to be the $1$ to $k$ substring of the current kmer plus the last base of the next kmer.  Figure \ref{fig:cortexrecords} lists three example records.  In the first record, the specified kmer has coverage $9$ in color $0$ (for our purposes, the child), $8$ in color $1$ (mother), and $5$ in color $2$ (father).  The trailing three columns encode edge information per color.  The first four characters of each column denote incoming edges to kmers with A, C, G, or T prefixes (or "." for no edge to that prefix).  The last four characters of each column denote outing edges to kmers with A, C, G, or T suffixes (or "." for no edge to that suffix).

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{cortexrecords}
  \caption{Example CortexRecord entries.}
  \label{fig:cortexrecords}
\end{figure}

The Cortex de Bruijn graph can be easily represented as a hash table where each key is a CortexKmer and the associated value a list of incoming and outgoing edges.  This enables lookups to be performed in $\mathcal{O}(1)$ time, but requires the entire graph be loaded into memory.  While this makes sense from the perspective of a software developer writing assembly software (where one would assume that every kmer will be processed during the lifetime of the program's execution), it is cumbersome for our purposes.  DNMs are anticipated to be scant, which implies that the number of kmers that need to be examined is modest.  Furthermore, should we wish to scale to larger genomes in the future (e.g. mammalian genomes on the order of $3$ gigabases), we must be aware of the much greater difficulty in loading such a graph entirely into memory (unless one happens to be operating on a computer with several hundred gigabytes of available RAM).  Instead, we sort the Cortex graphs and perform a binary search whenever we need to load the CortexRecord associated with a particular CortexKmer.  This increases the time complexity for kmer lookups to $\mathcal{O}(\log{}n)$, but eliminates the need to load the entire graph to memory.

We define a series of utility functions that aid graph traversal.  The \textbf{\texttt{findRecord}} method retrieves the CortexRecord indexed by a kmer via a binary search over the sorted disk-based graph, or throws an error if the graph is not sorted.  The CortexKmer within the CortexRecord, in addition to carrying the text of the kmer, also stores a bit that indicates whether the stored orientation matches the requested orientation, which is useful for navigation.  The methods \textbf{\texttt{getPrevKmers}} and \textbf{\texttt{getNextKmers}} retrieve lists of kmers connected to incoming and outgoing edges of the specified kmer, orientation-matched to the kmer \texttt{sk}.

Many methods will accept two graphs rather than just one: a \textbf{clean} graph and a \textbf{dirty} graph.  The clean graph represents data where errors have been removed by the assembly software's automatic filtering process (coverage and contig length considerations).  The dirty graph represents data prior to this cleaning step.  When a kmer is absent from the clean graph or lacks incoming/outgoing edges, traversal can still continue if the dirty graph contains the requested kmer and edge information.  This overcomes an issue wherein \textit{overcleaned} data (data filtered with too stringent a threshold) causes erroneous gaps in the graph.  If carefully used, the dirty graph can be used to patch these holes without causing significant errors in the traversal.  Almost all methods with this double graph signature have a form that look like Algorithm \ref{alg:doublegraph}, wherein a single graph version of the same method is called, only to be called again if the operation on the clean graph was unsuccessful. 

\begin{algorithm}
\caption{Get next kmers from the clean graph, failing back to the dirty graph}
\label{alg:doublegraph}
\begin{algorithmic}[1]
\Function{getNextKmers}{clean, dirty, kmer, color}
    \State nextKmers = getNextKmers(clean, kmer, color)

    \If{(dirty != null \&\& nextKmers.isEmpty())}
        \State nextKmers = getNextKmers(dirty, kmer, color)
    \EndIf

    \State return nextKmers
\EndFunction
\end{algorithmic}
\end{algorithm}

Finally, we present in Figure \ref{fig:uml} the UML diagram of the relevant parts of codebase encapsulating the relationships between \texttt{CortexGraph} (manager of access to underlying disk representation of the multi-color de Bruijn graph); \texttt{CortexRecord} (decodes graph records into kmer, coverage, and incoming/outgoing edges); \texttt{CortexKmer} (the kmer itself, along with orientation information); the utility method object \texttt{CortexUtils} (a collection of miscellaneous methods written to facilitate graph navigation); and the \texttt{AnnotatedVertex} and \texttt{AnnotatedEdge} objects (used to store subgraphs and metadata).

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{uml}
  \caption{Relationships between the \texttt{CortexGraph}, \texttt{CortexRecord}, \texttt{CortexKmer}, \texttt{CortexUtils}, \texttt{AnnotatedVertex}, and \texttt{AnnotatedEdge} objects.}
  \label{fig:uml}
\end{figure}

For clarity of the pseudocode presented below, we will refrain from referring to the object to which a method is bound.  For example, rather than specifying \texttt{CortexUtils.getNextKmer(...)} in an algorithm, we shall simply write \texttt{getNextKmer(...)}.  We \textit{will} refer to the parent object if doing so implies different data being accessed.  For example, \texttt{clean.findRecord(...)} and \texttt{dirty.findRecord(...)} refer to different data sources, the former being the error-cleaned data, the latter data that has not be processed in this manner.

\section{Variant motifs}
Just as reference-based methods search for motifs in the data representing variants (e.g. recurrent mismatches, gaps, or unusual truncations in the read alignments; read pairs aligning much further apart than expected; chimeras or inter-chromosomal alignments; etc.), so must we scan for indicative motifs in the assembly graph.  Before we discuss the precise nature of these motifs, it is useful to draw a distinction between "simple" and "complex" variants.  A "simple" variant is a SNP, insertion, or deletion that occurs within a single chromosome.  A "complex" variant could be a homologous or non-homologous recombination, translocation, or other interchromosomal exchange - something that does not fit within the confines of the straightforward SNP or indel classification.  The patterns inherent to these two categories of variants are very different.

\subsection{Simple variant motifs}
Simple variants in \textit{de novo} assembly data typically manifest as "bubbles" in the de Bruijn graph: regions where a variant has broken the homology between sequences, resulting in flanking kmers that are shared between the samples and spanning kmers that differ through the variant itself.  In a single diploid sample, this could be a heterozygous SNP or indel between two homologous chromosomes.  In a collection of haploid samples, one or more samples may differ from the others, resulting in the bubble.

As an illustration, consider three sequences from a mother-father-child pedigree, shown in Figure \ref{fig:db_graph_cartoon}a.  While the maternal and paternal haplotypes (green and blue, respectively) are identical, the child's haplotype (red) differs by a single C to G SNP.  Figure \ref{fig:db_graph_cartoon}b shows the resulting multi-color de Bruijn $k=3$ graph built from this data.  The mutation has given rise to the canonical bubble motif in the graph.  Three novel kmers (kmers present in the child and absent in the parents) spanning the variant allele are present.  Figure \ref{fig:snp_no_errors} is an equivalent graph for another simulated SNP, shown with more context and constructed with a much larger value of $k$ appropriate for $76$ - $100$ bp read lengths, typical of second-generation sequencing datasets (in this case, $k=47$).

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{db_graph_cartoon}
  \caption{A simple variant motif for a C to G SNP.  a. Haploid sequences from a mother (green), father (blue), and child (red), the last differing from the first two by a single base substitution.  b. The resulting multi-color de Bruijn graph for $k=3$.  Red vertices denote kmers that are deemed "novel", i.e. present in the child and absent in the parents. Edge colors reflect the samples in which the connected pairs of kmers are found. Edges that are part of the bubble (variant call) are displayed with thicker lines.}
  \label{fig:db_graph_cartoon}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{snp_no_errors}
  \caption{A multi-color de Bruijn graph at $k=47$ for a haploid pedigree spanning a simulated \textit{de novo} SNP, produced by our VisualCortex software.  Vertex labels have been supressed for clarity.  Spatial layout is arbitrary and for display purposes only.}
  \label{fig:snp_no_errors}
\end{figure}

All simple variants will have this basic structure: a bubble in the graph that separates the variant samples from the non-variant samples.  The only major difference is the length of each branch: longer for an insertion in the child, shorter for a deletion (note that for short events, this is generally not apparent from the display, as evidenced by Figures \ref{fig:ins_no_errors} and \ref{fig:del_no_errors}).

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{ins_no_errors}
  \caption{A $5$ bp insertion in the child}
  \label{fig:ins_no_errors}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{del_no_errors}
  \caption{A $5$ bp deletion in the child}
  \label{fig:del_no_errors}
\end{figure}

Many variants may occur on the haplotypic background of one parent and not the other.  This is common in regions of the genome that are divergent between the two parents.  Figure \ref{fig:td_haplotypic_background} depicts one such simulated event.  A 41-bp tandem duplication has occurred on the background of the mother (evidenced by the presence of green edges), but not the father (thus the absence of blue edges).  In the flanking tails, edges shared between all three samples are present until a blue edge separates from the graph and connects to different vertices.  While not shown, these branches continue along the genome of the father.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{td_haplotypic_background}
  \caption{A tandem duplication on the haplotypic background of the mother.}
  \label{fig:td_haplotypic_background}
\end{figure}

Finally, it is possible to encounter variants where the path through the graph taken by the child can appear to follow both the variant and non-variant paths, as demonstrated by Figure \ref{fig:inv_child_follows_parents}.  Such a scenario may arise by a mutation on a sequence with copy number greater than $1$: both the unaltered and altered sequences would then exist simultaneously in the child's genome.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{inv_child_follows_parents}
  \caption{A variant wherein the child's path does not simply diverge from that of the parents, but rather navigates both.}
  \label{fig:inv_child_follows_parents}
\end{figure}

\subsection{Complex variant motifs}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{gc}
  \caption{A gene conversion event}
  \label{fig:gc}
\end{figure}

Recombination events (allelic crossovers or gene conversion events; NAHR events) will not necessarily appear as bubbles.  Bubbles form in the graph when parental and progeny haplotypes diverge (at the site of a variant) and reconnect (at the flanking homologous regions).  In a recombination event, the haplotypes do not necessarily reconnect.  In a crossover or gene conversion event, as in Figure \ref{fig:gc}, the progeny's graph should follow one parent or the other, switching at the crossover site.  Gene conversions and other multiple crossovers may switch back and forth several times.  These events can be detected simply by keeping track of which parent's graph is apparently being followed.  However, we caution the reader that it's quite likely that many events of this nature will likely go uncalled or improperly called.  For such recombination events to be detected, a kmer spanning two proximal variants must be present.  This is unlikely to occur for simple crossovers, particularly in genomes of reasonably low heterozygosity, as neighboring variants beyond a kmer's length away will not give rise to novel kmers necessary for the event's detection.  It is perhaps slightly more likely for gene conversion events, where the multiple crossovers proximal to a variant exclusive to one of the parents will generate the sought-after novel kmer signal.

NAHR events are trickier; as these events are generally mitotic rather than meiotic events, the expected motif is that a child's graph should follow the same parent, but connect disjoint components of the graph (e.g. telomeres of different chromosomes) through novel kmers.  In principle, one should be able to detect such an event by testing whether removing the child's contribution to the pedigree subgraph results in disrupting the otherwise connected components\cite{Hopcroft:1971vx}.  In practice, however, NAHR events are mediated by homology between low-complexity regions of the subtelomeric genomic regions.  The homology will result in confounding connections between disparate regions of the graph.  An easier solution is to track the parent apparently being copied from and determine the chromosome of origin for each kmer present in the flanking regions of the novel kmers.  This is only feasible if one happens to have draft reference genomes for which a kmer's chromosome of origin can be approximately determined.

\subsection{Handling errors in sequencing}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{indel_with_errors_collapsed_and_expanded}
  \caption{Indel with sequencing errors in graph.  a. Selected extraneous branches expanded for illustrative purposes  b. All extraneous branches collapsed.}
  \label{fig:indel_with_errors_collapsed_and_expanded}
\end{figure}

Bubble and non-bubble motifs are trivial to find and navigate if there are no errors in the sequence data, but this situation rarely arises in real data.  Real data is subject to sequencing errors, making graph traversal much more difficult.  Errors manifest as extraneous branches in the graph, adding ambiguity to traversals.  Without a guide as to which branch to explore at a junction, we are either forced to abandon the traversal, make a guess, or explore all possible branches.  The first option is overly conservative; many variants will go untyped.  The second is hazardous; there is the very real potential for choosing erroneously and typing the variant incorrectly.  The last is computationally expensive; errors explode the complexity of the graph, making it prohibitively costly to find the correct path through the graph.

To solve this, recall that DNMs do more than open up a bubble motif in the graph.  Ideally, each kmer along the variant path is novel.  If we assume that branches following the novel branch at junctions are correct and linked with the current variant being explored, we can use these novel kmers as "sign posts" to mark successful traversals.  Navigating a branch and not seeing a sign post gives us adequate cause to abandon a branch in favor of another.

Figure \ref{fig:indel_with_errors_collapsed_and_expanded}a-b depict a simulated indel in imperfect data, the former with some of these extraneous branches displayed, the latter with them suppressed.  Branches with novel kmers (the red vertices) clearly complete the variant, while branches lacking these novel kmers are superfluous to the traversal and can be discarded without loss.  This limits the amount of unnecessary traversal in the graph, making it easier to find paths through the parental and child colors to form the variant.

\section{Calling and classifing \textit{de novo} variants}

Armed with an intuition as to how graphs behave in regions of \textit{de novo} variation, we can now describe the procedure for identifying and classifying a variant.  The overview involves five big steps (and associated substeps):

\begin{enumerate}
\item Identify confident and trusted novel kmers
\item Construct multi-color de Bruijn "trio" graphs (child, mother, father)
\item Load subgraph local to a novel kmer
\item Identify and classify variants in the subgraph
\item Evaluate performance
\end{enumerate}

We discuss these in details in the sections below.

\subsection{Identify confident and trusted novel kmers}

We first seek to build a list of novel kmers that are both \textit{confident} (i.e. unlikely to be sequencing errors) and \textit{trusted} (i.e. are unlikely to be the result of contamination).  Identification of the novel kmers themselves is trivial; we simply build a list of kmers that appear in the child but are completely absent in the parents.  The subsequent filtering steps are described below.

\subsubsection{Remove low coverage kmers}

For a deeply sequenced sample, we expect all kmers in the genome to be of similarly high coverage.  While there will inevitably be regions of the genome where coverage is poor owing to failure to amplify regions with high GC content, the Lander-Waterman statistics in Chapter \ref{ch:motivation} suggest we should easily see many copies of the entire \textit{P. falciparum} genome at a coverage of $100x$.  We can therefore assume that failure to reach a certain coverage threshold is indicative of sequencing error, and such kmers can be removed as candidates from the novel kmer list.

The problem remains as to where the threshold should be set.  For each sample, we plotted the histogram of kmer coverage, shown in Figure \ref{fig:covthreshold}, smoothing the resulting distribution with a non-parametric LOESS fit.  The smoothed histogram makes it easier to find the first local minimum using Algorithm \ref{alg:localminimum}.

\begin{algorithm}
\caption{Compute the local minimum of a kmer coverage distribution}
\label{alg:localminimum}
\begin{algorithmic}[1]
\Function{firstLocalMinimum}{coverageHist}
    \State y = laggedDifferences(c(INT\_MAX, x)) > 0L
    \State y = cumSum(equalRunLengths(y).lengths)
    \State y = y[seq(2L, length(y), 2L)]

    \State return(y[2])
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.9\textwidth]{covthreshold}
  \caption{Kmer coverage histogram for a real sample, with LOESS fit}
  \label{fig:covthreshold}
\end{figure}

\subsubsection{Remove possible contaminants}

Contamination can occur during sequencing library preparation due to handling from human operators (transferring either bacterial or human genetic material to the library) or from other samples (often from different species) being processed in the same laboratory.  Contamination would result in kmers that appear novel - owing to their absense in the parents - but are irrelevant for our study.  It is perhaps not a paramount concern when processing \textit{P. falciparum} data, as the genome is very different than any other sample likely to be a contaminant.  However, it may contribute false-positives that we can easily mitigate.

To remove the effects of contamination, we run every confident novel kmer through BLAST\cite{Altschul:1990dw}.  Specifically, we used the \texttt{blastn} package and all available BLAST nucleotide databases to identify the likely species of every confident novel $47$-mer in each sample.  Any unidentified kmer or apparently \textit{P. falciparum} kmer was retained; all others were removed.  In practice, this removes anywhere from dozens to thousands of kmers from needing to be considered; as evidenced by Figure \ref{fig:contam}, the exact number varies as each sample is prepared independently, at different times and by different personnel.

\begin{sidewaysfigure}[h!]
  \centering
    \includegraphics[width=\textwidth]{contam}
  \caption{Removal of contaminating kmers; \textit{P. falciparum} kmers are shown in green; the putative contaminants are shown in orange.}
  \label{fig:contam}
\end{sidewaysfigure}

\subsection{Construct multi-color de Bruijn "trio" graphs}

To construct the "trio" graphs, we perform assembly on each sample with the \textit{Cortex} \textit{de novo} assembly software\cite{Iqbal:2012fx} following the recommended workflow\cite{Turner:2015ve}.  Briefly, each sample is assembled using the \texttt{build} command at a kmer size of $47$ bp\footnote{This setting results from evaluations on optimal kmer size for maximizing contig length, despite not needing to produce contigs for our analyses} and ignoring nucleotides with an Illumina quality score less than $5$.  Each sample was then cleaned of likely sequencing errors with the \texttt{clean} command using automatically calculated coverage and supernode (unambiguous runs of kmers with in/out degree of $1$) length thresholds.  Finally, the graph for the child was merged into a \textit{clean} trio graph, and separately, a \textit{dirty} trio graph (one using the uncleaned graph data) using the \texttt{join} command.  This multi-color graph consists of child, mother, and father.  For our purposes with \textit{P. falciparum}, "child" is assigned color $0$, "mother" (the first parent of the cross) to color $1$, and "father" to color $2$.  Read threading was \textit{not} applied, as in our analyses, there is no need for contigs, just the graph data structure.

\subsection{Load subgraph local to a novel kmer}

To facilitate variant calling, we must process regions of the graph likely to harbor DNMs.  While it is technically possible to load a \textit{P. falciparum} graph into RAM (owing to its small $23$ megabase genome), it is unlikely such a solution would scale to larger genomes.  It is also cumbersome to do so when there are only on the order of dozens, perhaps hundreds, of variants to be discovered per genome.  Therefore, we adopted a solution of fetching only relevant parts of the genome as necessary, operating on the local subgraph surrounding the putative variant, rather than on the entire graph at once.

\subsubsection{Depth-first search}

Graph exploration is an \textit{online} problem, meaning the structure of the graph cannot be known until it is explored.  As a non-linear data structure, it is not trivial to determine where to start and stop exploring a graph.  During traversal, one may encounter junctions (due to errors or homology) without any additional information as to which branch to choose.  Graphs sometimes loop back onto themselves, necessitating that we keep track of our walk so that we do not end up traversing endlessly in circles.  Incorrect decisions in the traversal cannot always be detected, requiring appropriate stopping conditions to abort a traversal if no fruitful data is discovered.

Typically, graph exploration can be accomplished with a so-called \textit{depth-first search}, or DFS.  The basic premise of a DFS is summarized in Algorithm \ref{alg:dfs}: start at a vertex, walk in a chosen direction until a junction is encountered, choose one branch and repeat the DFS from that point until it is deemed appropriate to stop, then jump back to the junction to choose the next branch, and repeat until completion.  In practice, this approach has some drawbacks that manifest quickly in real data.  First, the basic DFS algorithm terminates only when there are no more vertices left to traverse, which is overkill for our purposes.  Second, all branches are treated equally.  For our purposes, branches containing errors are not important and should be discarded lest they confuse later algorithms trying to find paths through bubbles in order to type variants.  Third, this requires us to explore three graphs separately, which is inefficient.

\begin{algorithm}
\caption{A basic, iterative depth-first search}
\label{alg:dfs}
\begin{algorithmic}[1]
\Function{idfs}{graph, vertex}
  \State $s = \textrm{new Stack()}$
  \State $\textrm{visited} = \{\}$
  \State $\textrm{s.push(vertex)}$

  \While{\textrm{!s.isEmpty()}}
    \State $current = s.pop()$
    \If{($\textrm{visited.contains(current)}$)}
        \State $\textrm{next}$
    \EndIf
    \State $\textrm{visited.add(current)}$

    \For{$\textrm{v in graph.nextVertices(vertex)}$}
        \State $\textrm{s.push(v)}$
    \EndFor
  \EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

The solution is to instead conduct a DFS with stopping conditions and recursively.  Stopping conditions, specifying the conditions upon which a traversal is deemed "successful" or "failed" allow us to decide certain branches in the subgraph are unfruitful for analysis.  The recursive traversal allows us to act on the result of the stopping condition, adding it to the subgraph if successful, discarding it if not.  This is described in Algorithm \ref{alg:rdfs}.

\begin{algorithm}
\caption{The recursive depth-first search with arbitrary stopping conditions}
\label{alg:rdfs}
\begin{algorithmic}[1]
\Function{rdfs}{clean, dirty, kmer, color, g, stopper, depth, goForward, history}
    \State firstKmer = kmer

    \State sourceKmersAllColors = goForward ? getPrevKmers(clean, dirty, kmer) : getNextKmers(clean, dirty, kmer)
    \State sourceKmers = sourceKmersAllColors.get(color)

    \State dfs = new AnnotatedGraph()

    \Repeat
        \State cv = kmer

        \State cr = clean.findRecord(cv)
        \If{(cr == null \&\& dirty != null)}
            \State cr = dirty.findRecord(cv)
        \EndIf

        \State prevKmers = getPrevKmers(clean, dirty, cv)
        \State nextKmers = getNextKmers(clean, dirty, cv)
        \State adjKmers  = goForward ? nextKmers : prevKmers

        \State addVertexAndConnect(dfs, cv, prevKmers, nextKmers)

        \If{(stopper.keepGoing(cr, g, depth, dfs.vertexSet().size(), adjKmers.get(color).size()) \&\& !history.contains(kmer))}
            \State history.add(kmer)

            \If{(adjKmers.get(color).size() == 1)}
                \State kmer = next(adjKmers.get(color))
            \ElsIf{(adjKmers.get(color).size() != 1)}
                \State childrenWereSuccessful = false

                \For{(ak in adjKmers.get(color))}
                    \State branch = dfs(clean, dirty, ak, color, g, stopperClass, depth + isNovelKmer(cr) ? 0 : 1, goForward, history)

                    \If{(branch != null)}
                        \State addGraph(dfs, branch)
                        \State childrenWereSuccessful = true
                    \EndIf
                \EndFor

                \If{(childrenWereSuccessful || stopper.hasTraversalSucceeded(cr, g, depth, dfs.vertexSet().size(), 0))}
                    \State return dfs
                \EndIf
            \EndIf
        \ElsIf{(stopper.traversalSucceeded())}
            \State return dfs
        \Else
            \State return null
        \EndIf
    \Until{(adjKmers.get(color).size() == 1)}

    \State return null
\EndFunction
\end{algorithmic}
\end{algorithm}

Stopping conditions are implemented as a callback object, permitting programmer-specified limits for different situations.  To type DNMs, we begin traversal at a novel kmer, walking forward and backward in the graph until the stopping conditions are met.  We then explore the parental graphs based on the subgraph we loaded for the child.  As the parental traversals have some additional information (namely, the presence of the child's subgraph allows us to check if a parental traversal has diverged and rejoined from the graph), the stopping conditions are different.

The stopping condition callback object implements two boolean methods: \texttt{hasTraversalSucceeded} and \texttt{hasTraversalFailed}.  Both of them may return \texttt{false}, in which case the traversal continues.  If either returns \texttt{true}, traversal is halted and the branch is evaluated for retention or rejection.

\subsubsection{Stopping conditions for child}

The child's stopping conditions on traversal success or failure are provided in Algorithm \ref{alg:child_hasTraversalSucceded} and \ref{alg:child_hasTraversalFailed}, respectively.  For the child, success is approximately determined by having explored a novel kmer stretch in the graph to the point that it has rejoined the parental graphs.  However, we purposefully continue reading another $50$ kmers before returning success.  If more novel kmers are recovered in that span, we reset our counters and continue walking.  This facilitates two things: the absence of novel kmers due to sequencing errors or overthresholding, and typing complex variants that may have short stretches of non-novel kmers.  Failure is determined by a number of criteria, including the absence of novel kmers, low complexity regions, having no more branches to explore, having reached a maximum graph depth, or having reached a maximum graph size.

\begin{algorithm}
\caption{Child's traversal success determination method}
\label{alg:child_hasTraversalSucceded}
\begin{algorithmic}[1]
\Function{hasTraversalSucceeded}{cr, g, depth, size, edges}
    \If{(goalSize == 0 \&\& (cr.getCoverage(1) > 0 || cr.getCoverage(2) > 0))}
        \State goalSize = size
        \State goalDepth = depth
    \EndIf

    \If{(goalSize > 0 \&\& isNovel(cr))}
        \State goalSize = size
        \State goalDepth = depth
    \EndIf

    \State return (goalSize > 0 \&\& (size >= goalSize + 50 || isLowComplexity(cr) || edges == 0))
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Child's traversal failure determination method}
\label{alg:child_hasTraversalFailed}
\begin{algorithmic}[1]
\Function{hasTraversalFailed}{cr, g, depth, size, edges}
    \State return !isNovel(cr) \&\& (isLowComplexity(cr) || edges == 0 || depth >= 5 || size > 5000)
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Stopping conditions for parents}

The parents' stopping conditions on traversal success or failure are provided in Algorithm \ref{alg:parent_hasTraversalSucceded} and \ref{alg:parent_hasTraversalFailed}, respectively.  Success is determined by having diverged from the child's graph and rejoined it.  Care is taken to ensure that we have rejoined the graph at a boundary of the novel kmer stretch, rather than some ther part of the graph obtained when trying to read some extra flanking data in Algorithm \ref{alg:child_hasTraversalSucceded}.  Failure is determined by a number of criteria, including having reached a maximum graph size, having reached a maximum graph depth, or low complexity regions.

\begin{algorithm}
\caption{Parents' traversal success determination method}
\label{alg:parent_hasTraversalSucceded}
\begin{algorithmic}[1]
\Function{hasTraversalSucceeded}{cr, g, depth, size, edges}
    \State fw = cr.getKmerAsString()
    \State rc = reverseComplement(fw)
    \State v = null
    \State rejoinedGraph = false

    \If{(g.containsVertex(fw) || g.containsVertex(rc))}
        \State rejoinedGraph = true

        \For{av in g.vertexSet()}
            \If{ (av.getKmer().equals(fw) || av.getKmer().equals(rc)) }
                \If{ (!sawPredecessorFirst \&\& !sawSuccessorFirst) }
                    \If{ (av.flagIsSet("predecessor")) }
                        sawPredecessorFirst = true 
                    \ElsIf{ (av.flagIsSet("successor")) }
                        sawSuccessorFirst = true 
                    \EndIf
                \EndIf

                \If{ ((sawPredecessorFirst \&\& av.flagIsSet("predecessor")) || (sawSuccessorFirst \&\& av.flagIsSet("successor"))) }
                    \State rejoinedGraph = false
                    \State break
                \EndIf
            \EndIf
        \EndFor
    \EndIf

    \State return size > 1 \&\& rejoinedGraph
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Parents' traversal failure determination method}
\label{alg:parent_hasTraversalFailed}
\begin{algorithmic}[1]
\Function{hasTraversalFailed}{cr, g, depth, size, edges}
    \State return size > 1000 || junctions >= 5 || isLowComplexity(cr)
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Identify and classify variants in the subgraph}

With the relevant subgraph now loaded, we can now attempt to type variants.  Typing involves three steps:

\begin{enumerate}
\item Annotate vertices in the graph that can be possible start and end points of the variant bubble
\item Find the shortest path from start to end that satisfies some conditions
\item From the haplotypes, remove the flanking homologous sequence to reveal the variant alleles
\end{enumerate}

Let us first detail how we annotate the viable starts and ends of the variant, which simply amounts to iterating through each vertex in the subgraph and checking that it means various conditions.  A variant start (end) vertex should have out degree (in degree) greater than $1$.  The branches should be color-specific to reflect the opening of a bubble between the different samples in the graph.  This is detailed in Algorithm \ref{alg:annotate_subgraph}.

\begin{algorithm}
\caption{Annotating possible variant starts and ends of the subgraph}
\label{alg:annotate_subgraph}
\begin{algorithmic}
\Function{annotateStartsAndEnds}{b}
    \For{av in b.vertexSet()}
        \If{(b.outDegreeOf(av) > 1)}
            \State aes = b.outgoingEdgesOf(av)

            \State childEdges = \{\}
            \State parentEdges = \{\}

            \For{(AnnotatedEdge ae in aes)}
                \If{(ae.isPresent(0) \&\& ae.isAbsent(1) \&\& ae.isAbsent(2))} 
                    \State childEdges.add(ae)
                \EndIf

                \If{(ae.isPresent(color))}
                    \State parentEdges.add(ae)
                \EndIf
            \EndFor

            \If{(childEdges.size() > 0 \&\& parentEdges.size() > 0)}
                \State av.setFlag("start")
                \State candidateStarts.add(av)
            \EndIf
        \EndIf

        \If{(b.inDegreeOf(av) > 1)}
            \State aes = b.incomingEdgesOf(av)

            \State childEdges = \{\}
            \State parentEdges = \{\}

            \For{AnnotatedEdge ae in aes}
                \If{ae.isPresent(0) \&\& ae.isAbsent(1) \&\& ae.isAbsent(2)}
                    \State childEdges.add(ae)
                \EndIf

                \If{ae.isPresent(color)}
                    \State parentEdges.add(ae)
                \EndIf
            \EndFor

            \If{(childEdges.size() > 0 \&\& parentEdges.size() > 0) || beAggressive} 
                \State av.setFlag("end")

                \State candidateEnds.add(av)
            \EndIf
        \EndIf
    \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Dijkstra's shortest path algorithm}

With all of the start and end points now annotated, we now need to find a path from one end of the putative variant to the other.  The number of possible paths could be very large.  We shall make the assumption that the correct path is the shortest path.  While this will often be the case, we note that the shortest path is not necessarily the biological path.  This could be the case in highly repetitive regions longer than a kmer length.  Since de Bruijn graphs tend to collapse long repeats, we may miss some events.

E. W. Dijkstra described his shortest path algorithm in 1959\cite{Dijkstra:1959cw}.  We describe it below in Algorithm \ref{alg:dijkstra}.  Briefly, we keep track of all vertices' distance from the source vertex, setting the source's distance to itself to $0$ and all others to infinity (to denote as-of-yet unvisited vertices).  We then select the vertex with the minimum distance to the source (in the first iteration, the source itself) and compute a new distance to all immediately adjacent vertices.  This new distance is a sum of the distance traversed so far from the source to one of these vertices.  For our purposes, we shall assume the distance between two adjacent vertices is always $1$.  If the distance computed is less than the distance recorded, we replace the old value with the new.  We remove this vertex from the processing queue and proceed to the next vertex with the lowest distance from the source.

\begin{algorithm}
\caption{Finding the shortest path in a graph}
\label{alg:dijkstra}
\begin{algorithmic}
\Function{dspa}{graph, source, destination, color}
    \State dist = \{\}
    \State prev = \{\}
    \State q = []

    \ForAll{v in g.vertexSet()}
        \State dist[v] = infinity
        \State prev[v] = null
        \State push(q, v)
    \EndFor

    \State dist[source] = 1

    \While{!q.isEmpty()}
        \State u = vertexWithMinDistance(q, dist)

        \If{u == destination}
            \State break
        \EndIf

        \State q.remove(u);

        \If{u != -1}
            \ForAll{e in g.outgoingEdgesOf(u, color)}
                \State v = g.getEdgeTarget(e, color)

                \State alt = dist[u] + 1

                \If{alt < dist[v]}
                    \State dist[v] = alt
                    \State prev[v] = u
                \EndIf
            \EndFor
        \EndIf
    \EndWhile

    \State s = []
    \State Integer u = destination

    \While{u != null \&\& prev.containsKey(u)}
        \State push(s, u)
        \State u = prev[u]
    \EndWhile

    \State return s
\EndFunction
\end{algorithmic}
\end{algorithm}

To use this algorithm for allele identification, we iterate through all possible combinations of start and stop vertices, obtained as described in the previous section.  We then iterate through the three graph colors (representing the child, mother, and father).  For each color, we apply Algorithm \ref{alg:dijkstra}.  For the child, we place the additional constraint that the path accepted must contain at least one novel kmer.

This algorithm will return the child and parental haplotypes.  To identify the precise alleles of the event, we simply trim back the homologous regions of the haplotypes with Algorithm \ref{alg:trim}.

\begin{algorithm}
\caption{Trim back haplotypes to reveal alleles}
\label{alg:trim}
\begin{algorithmic}
\Function{trimHaplotypes}{child, parent}
    \State e0 = child.length() - 1
    \State e1 = parent.length() - 1
    \State s = 0
    \State length = (child.length() < parent.length() ? child.length() : parent.length())

    \For{(s = 0; s < length \&\& child[s] == parent[s]; s++)}
        \State (do nothing)
    \EndFor

    \While{(e0 > s \&\& e1 > s \&\& child[e0] == parent[e1])}
        \State e0--
        \State e1--
    \EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Classify event}

For simple variants (those that conform to the bubble motif), event classification is reasonably straightforward.  We simply inspect the recovered alleles and evaluate them against simple rules.  For example, a SNP should be a single nucleotide in length.  An insertion should have a parental allele length of $1$ and a child allele length $> 1$.

To classify complex variants, we rely on other heuristics.  GC events are classified by keeping track of which parent the child's genome appears to be exclusively copying from (simply by measuring when kmer coverage has dropped from one parent and returned in the other), detailed in Algorithm \ref{alg:hasSwitches}.  NAHR events, involving recombinations between different chromosomes, are detected by examining if any kmers are uniquely found on different chromosomes, detailed in Algorithm \ref{alg:hasChimeras}.

\begin{algorithm}
\caption{Stretch has switches}
\label{alg:hasSwitches}
\begin{algorithmic}
\Function{hasSwitches}{graph, stretch}
    \State inherit = []
    \ForAll{$47$-bp kmers $k$ in stretch}
        \State cov0 = graph.getCoverage(k, 0) \Comment child
        \State cov1 = graph.getCoverage(k, 1) \Comment mother
        \State cov2 = graph.getCoverage(k, 2) \Comment father

        \If{(cov0 > 0 \&\& cov1 == 0 \&\& cov2 == 0)}
            \State append(inherit, "C")
        \ElsIf{(cov0 > 0 \&\& cov1 > 0 \&\& cov2 == 0)}
            \State append(inherit, "M")
        \ElsIf{(cov0 > 0 \&\& cov1 == 0 \&\& cov2 > 0)}
            \State append(inherit, "D")
        \ElsIf{(cov0 > 0 \&\& cov1 > 0 \&\& cov2 > 0)}
            \State append(inherit, "B")
        \EndIf
    \EndFor

    \For{i in inherit.length()}
        \For{inherit[i] == 'B'}
            \State prevContext = '?'
            \State nextContext = '?'

            \For{(j = i - 1; j >= 0; j--)}
                \If{(inherit[j] == 'M' || inherit[j] == 'D')}
                    \State prevContext = inherit[j]
                    \State break
                \EndIf
            \EndFor

            \For{(j = i + 1; j < inherit.length(); j++)}
                \If{(inherit[j] == 'M' || inherit[j] == 'D')}
                    \State nextContext = inherit[j];
                    \State break;
                \EndIf
            \EndFor

            \State context = '?';
            \If{(prevContext == nextContext \&\& prevContext != '?')}
                \State context = prevContext
            \ElsIf{(prevContext != nextContext)}
                \If{(prevContext != '?')}
                    \State context = prevContext
                \Else
                    \State context = nextContext
                \EndIf
            \EndIf

            \State inherit[i] = context
        \EndFor
    \EndFor

    \State return inheritStr.matches(".*D+.C+.M+.*") || inheritStr.matches(".*M+.C+.D+.*")
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Stretch has chimeras}
\label{alg:hasChimeras}
\begin{algorithmic}
\Function{hasChimeras}{stretch, lookup}
    \State chrCount = \{\}

    \ForAll{kmers k in stretch}
        \If{lookup.numAlignments(k) == 1}
            \State chrCount[lookup.getFirstAlignment(k).getChr()]++
        \EndIf
    \EndFor

    \State return chrCount.size() > 1
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{classification}
  \caption{}
  \label{fig:classification}
\end{figure}

The classification algorithm can be described by the decision tree in Figure \ref{fig:classification}.

\subsubsection{Choosing haplotypic background}

When calling variants, we do not know the haplotypic background upon which a variant has occured.  We must compare the child's graph to the mother's and then to the father's, making separate calls.  This results in two variant calls for the same event.  A single event must be chosen.  In cases where the child and parental alleles are identical, this is trivial.  Additionally, variants where the event can be identified against one parent but not the other are straightforward.  The problematic events are those that have conflicting descriptions between parents.  In this situation, we heuristically assign a score for various properties of the variant, choosing the representation with the highest score.  This has the effect of preferring simpler descriptions (e.g. "SNP") to more complex ones (e.g. "GC").

\begin{algorithm}
\caption{Score variant}
\label{alg:scoreVariant}
\begin{algorithmic}
\Function{chooseVariant}{gvc}
    \State scores = []

    \ForAll{colors c}
        \If{(gvc.traversalIsComplete(c))}
            \State scores[c]++
        \EndIf
        \If{(gvc.variantType(c) != "unknown"}
            \State scores[c]++
        \EndIf
        \If{(gvc.variantType(c) not in ("GC", "NAHR"))}
            \State scores[c]++
        \EndIf
    \EndFor

    \State bestColor = whichMax(scores)

    \State return (scores[0] == scores[1] ? 0 : bestColor)
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Mark traversed novel kmers as used}

We then mark all the novel kmers we saw used in the stretch as used so we do not process them again.  This allows us to keep track of our progress, only acting on kmers that have not been associated to any variant yet.

\subsection{Evaluate performance}

We evaluated the performance of our graphical DNM caller by running the thing on some simulated data.  Note that the way a variant is simulated and the way a variant is called are not necessarily identical.  In particular, indels are tricky because there is not a standard representation in graphs.  Usually, when indels are called in reference-based methods, the reference is taken to be the forward strand and indels are left-shifted as far as possible.  In graphs, there is no information available for determining orientation.  When they were simulated, we knew what the forward strand was, but we do not know that in the graph.  Thus, when we go to check on the presence of a variant, we must check it in both orientations, and accounting for multiple representations.

\subsubsection{Pre-compute novel kmer to variant map}

We iterated through all variants, extracting sequence from the simulated child's reference genome between $\textrm{start} - (2k - 1)$ and $\textrm{stop} + (2k - 1)$ bp.  We then extracted each kmer from this sequence and, if the kmer is novel, emitting a table row mapping the novel kmer to variant ID, variant type, and position in the child's reference genome.  Note that because we chose to space our variants out over considerable distance, it is generally not possible for a kmer to map to multiple variants.  However, as we have placed very few constraints on variant positioning otherwise, it is possible a simulated variant has landed in a low-complexity region that occurs multiple times throughout the genome, and that multiple variants thus share novel kmers.  In that instance, the first variant we see during processing is assigned the novel kmer.

\subsubsection{Load variant containing a novel kmer and comparing}

If we are in evaluation mode (that is, if we've a novel kmer to variant map along with a dataset), then after each variant we call, we check if any of the kmers involved in the variant call are in the map, and load the relevant variant information.  We then evaluate our call using Algorithm \ref{alg:evalVariant}.

\begin{algorithm}
\caption{Evaluate variant}
\label{alg:evalVariant}
\begin{algorithmic}
\Function{evalVariant}{call, truth, stretch}
    \State relevantVariants = []

    \ForAll{kmers in stretch}
        \If{(truth.contains(kmer))}
            \State push(relevantVariants, truth.get(kmer))
        \EndIf
    \EndFor

    \State bestVariant = null;
    \ForAll{vi in relevantVariants}
        \State ref = call.getParentalAllele()
        \State alt = call.getChildAllele()

        \State refStretch = call.getParentalStretch()
        \State altStretch = call.getChildStretch()

        \State found = false;

        \If{(!found)}
            \Comment left-shift variants and check
            \State pos = call.getStart()

            \While{(pos >= 0 \&\& pos + ref.length() < refStretch.length() \&\& pos + alt.length() < altStretch.length())}
                \State refFw = refStretch.substring(pos, pos + ref.length())
                \State altFw = altStretch.substring(pos, pos + altLength)

                \State refRc = reverseComplement(refFw);
                \State altRc = reverseComplement(altFw)

                \If{(known ref and alt alleles match called fw or rc alleles)}
                    \State ref = (refFw or refRc)
                    \State alt = (altFw or altRc)
                    \State found = true;
                    \State break;
                \EndIf

                \State pos--
            \EndWhile
        \EndIf

        \If{(!found)}
            \Comment right-shift variants and check
            \State pos = call.getStart()

            \While{(pos >= 0 \&\& pos + ref.length() < refStretch.length() \&\& pos + alt.length() < altStretch.length())}
                \State refFw = refStretch.substring(pos, pos + refLength)
                \State refRc = reverseComplement(refFw)

                \State altFw = altStretch.substring(pos, pos + altLength)
                \State altRc = reverseComplement(altFw)

                \If{(known ref and alt alleles match called fw or rc alleles)}
                    \State ref = (refFw or refRc)
                    \State alt = (altFw or altRc)
                    \State found = true;
                    \State break;
                \EndIf

                \State pos++
            \EndWhile
        \EndIf

        \Comment Maybe what we've found is a truncated version of what we were expecting
        \State knownRef = vi.ref
        \State knownAlt = vi.alt == null ? "" : vi.alt

        \If{(!found \&\& knownRef.length() > ref.length() \&\& knownAlt.length() > alt.length() \&\& knownRef.length() == knownAlt.length())}
            \State refFw = ref;
            \State altFw = alt;
            \State refRc = reverseComplement(refFw);
            \State altRc = reverseComplement(altFw);

            \State refFinal = null, altFinal = null;

            \If{(knownRef contains refFw or refRc and knownAlt contains altFw or altRc)}
                \State refFinal = (refFw or refRc)
                \State altFinal = (altFw or altRc)
            \EndIf

            \If{(refFinal != null \&\& altFinal != null)}
                \State r0index = knownRef.indexOf(refFinal)
                \State a0index = knownAlt.indexOf(altFinal)
                \State r1index = r0index + refFinal.length()
                \State a1index = a0index + altFinal.length()

                \If{(r0index == a0index \&\& r1index == a1index \&\&
                        knownRef.substring(0, r0index).equals(knownAlt.substring(0, a0index)) \&\&
                        knownRef.substring(r1index, knownRef.length()).equals(knownAlt.substring(a1index, knownAlt.length())))}
                    knownRef = ref;
                    knownAlt = alt;
                \EndIf
            \EndIf
        \EndIf

        \State vi.found = true;
        \State vi.matches = (knownRef.equals(ref) \&\& knownAlt.equals(alt)) || vi.type.equals(call.getType())

        \If{(bestVi == null || vi.matches)}
            \State bestVi = vi;
        \EndIf

        \If{(bestVi != null)}
            \State knownRef = bestVi.ref;
            \State knownAlt = bestVi.alt != null ? bestVi.alt : "";
        \EndIf
    \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\section{Results on simulated data}

We ran our algorithm on the perfect and realistic simulated datasets presented in Chapter \ref{ch:simulation}.  Looking first at purely event recovery without classification (i.e. did we find \textit{de novo} variants, irrespective of whether we classified them correctly), we summarize our stats in Tables \ref{tbl:roc_perfect} and \ref{tbl:roc_realistic}.  In both cases, our sensitivity and specificity to DNMs is very high - greater than $98\%$ in nearly all cases.  Note that the true negatives (tn) are effectively every kmer that we did \textit{not} call in our dataset, which effecitvely makes our specificity nearly perfect, as the use of the novel kmers prevents us from making calls in the vast majority of the graph.

Additionally in these tables, we also computed the "redundant call", or "rc" metric.  The rc metric reveals an important caveat regarding graph calls: should the traversals fail and the alleles of the variant not ascertained, the novel kmers involved in the variant will not be marked as used.  However, we still emit a variant "event", despite our inability to classify it.  In the subsequent iteration of the algorithm, the remaining novel kmers will be picked up for calling again, leading to the same variant being emitted multiple times.  Thus, we must exercise caution with untyped variants: the rate at which they appear in our callset may be slightly higher (up to $10\%$) than the rate at which they truly exist in the genome.

\begin{sidewaystable}[]
\centering
\caption{ROC metrics on simulated perfect data}
\label{tbl:roc_perfect}
\begin{tabular}{rlrrrrrrrrrrrrr}
\toprule
sn & sim & fp & fn & tp & tn & rc & sens & spec & prec & npv & fpr & fnr & fdr & acc\\
\midrule
5 & perfect & 1 & 5 & 126 & 22240910 & 9 & 0.9618 & 1 & 0.9921 & 1 & 0 & 0.0382 & 0.0079 & 1\\
3 & perfect & 2 & 3 & 154 & 22200660 & 4 & 0.9809 & 1 & 0.9872 & 1 & 0 & 0.0191 & 0.0128 & 1\\
0 & perfect & 0 & 2 & 106 & 22241343 & 7 & 0.9815 & 1 & 1.0000 & 1 & 0 & 0.0185 & 0.0000 & 1\\
12 & perfect & 0 & 2 & 113 & 22233659 & 3 & 0.9826 & 1 & 1.0000 & 1 & 0 & 0.0174 & 0.0000 & 1\\
13 & perfect & 0 & 2 & 114 & 22217297 & 5 & 0.9828 & 1 & 1.0000 & 1 & 0 & 0.0172 & 0.0000 & 1\\
17 & perfect & 0 & 2 & 117 & 22242890 & 6 & 0.9832 & 1 & 1.0000 & 1 & 0 & 0.0168 & 0.0000 & 1\\
1 & perfect & 1 & 2 & 137 & 22249556 & 8 & 0.9856 & 1 & 0.9928 & 1 & 0 & 0.0144 & 0.0072 & 1\\
14 & perfect & 2 & 2 & 162 & 22196410 & 7 & 0.9878 & 1 & 0.9878 & 1 & 0 & 0.0122 & 0.0122 & 1\\
11 & perfect & 1 & 1 & 114 & 22207761 & 2 & 0.9913 & 1 & 0.9913 & 1 & 0 & 0.0087 & 0.0087 & 1\\
6 & perfect & 1 & 1 & 118 & 22203683 & 2 & 0.9916 & 1 & 0.9916 & 1 & 0 & 0.0084 & 0.0084 & 1\\
8 & perfect & 1 & 1 & 129 & 22229379 & 5 & 0.9923 & 1 & 0.9923 & 1 & 0 & 0.0077 & 0.0077 & 1\\
10 & perfect & 0 & 1 & 130 & 22238480 & 2 & 0.9924 & 1 & 1.0000 & 1 & 0 & 0.0076 & 0.0000 & 1\\
15 & perfect & 1 & 1 & 131 & 22208991 & 10 & 0.9924 & 1 & 0.9924 & 1 & 0 & 0.0076 & 0.0076 & 1\\
16 & perfect & 1 & 1 & 166 & 22213928 & 4 & 0.9940 & 1 & 0.9940 & 1 & 0 & 0.0060 & 0.0060 & 1\\
2 & perfect & 1 & 0 & 105 & 22225262 & 3 & 1.0000 & 1 & 0.9906 & 1 & 0 & 0.0000 & 0.0094 & 1\\
4 & perfect & 2 & 0 & 72 & 22210167 & 2 & 1.0000 & 1 & 0.9730 & 1 & 0 & 0.0000 & 0.0270 & 1\\
7 & perfect & 1 & 0 & 57 & 22225612 & 1 & 1.0000 & 1 & 0.9828 & 1 & 0 & 0.0000 & 0.0172 & 1\\
9 & perfect & 0 & 0 & 107 & 22255460 & 2 & 1.0000 & 1 & 1.0000 & 1 & 0 & 0.0000 & 0.0000 & 1\\
18 & perfect & 2 & 0 & 133 & 22242522 & 0 & 1.0000 & 1 & 0.9852 & 1 & 0 & 0.0000 & 0.0148 & 1\\
19 & perfect & 1 & 0 & 98 & 22236313 & 6 & 1.0000 & 1 & 0.9899 & 1 & 0 & 0.0000 & 0.0101 & 1\\
\bottomrule
\end{tabular}
\end{sidewaystable}

\begin{sidewaystable}[]
\centering
\caption{ROC metrics on simulated realistic data}
\label{tbl:roc_realistic}
\begin{tabular}{rlrrrrrrrrrrrrr}
\toprule
sn & sim & fp & fn & tp & tn & rc & sens & spec & prec & npv & fpr & fnr & fdr & acc\\
\midrule
5 & realistic & 4 & 2 & 123 & 77566161 & 7 & 0.9840 & 1 & 0.9685 & 1 & 0 & 0.0160 & 0.0315 & 1\\
0 & realistic & 1 & 1 & 101 & 77516712 & 7 & 0.9902 & 1 & 0.9902 & 1 & 0 & 0.0098 & 0.0098 & 1\\
6 & realistic & 2 & 1 & 107 & 77289511 & 2 & 0.9907 & 1 & 0.9817 & 1 & 0 & 0.0093 & 0.0183 & 1\\
13 & realistic & 0 & 1 & 107 & 77362132 & 3 & 0.9907 & 1 & 1.0000 & 1 & 0 & 0.0093 & 0.0000 & 1\\
17 & realistic & 3 & 1 & 109 & 77390562 & 5 & 0.9909 & 1 & 0.9732 & 1 & 0 & 0.0091 & 0.0268 & 1\\
12 & realistic & 2 & 1 & 111 & 77440516 & 3 & 0.9911 & 1 & 0.9823 & 1 & 0 & 0.0089 & 0.0177 & 1\\
16 & realistic & 1 & 1 & 155 & 77369055 & 5 & 0.9936 & 1 & 0.9936 & 1 & 0 & 0.0064 & 0.0064 & 1\\
2 & realistic & 4 & 0 & 93 & 77425427 & 1 & 1.0000 & 1 & 0.9588 & 1 & 0 & 0.0000 & 0.0412 & 1\\
4 & realistic & 3 & 0 & 65 & 77312705 & 2 & 1.0000 & 1 & 0.9559 & 1 & 0 & 0.0000 & 0.0441 & 1\\
3 & realistic & 6 & 0 & 150 & 77296380 & 1 & 1.0000 & 1 & 0.9615 & 1 & 0 & 0.0000 & 0.0385 & 1\\
1 & realistic & 1 & 0 & 133 & 77509177 & 5 & 1.0000 & 1 & 0.9925 & 1 & 0 & 0.0000 & 0.0075 & 1\\
7 & realistic & 4 & 0 & 56 & 77445270 & 1 & 1.0000 & 1 & 0.9333 & 1 & 0 & 0.0000 & 0.0667 & 1\\
8 & realistic & 6 & 0 & 126 & 77469034 & 3 & 1.0000 & 1 & 0.9545 & 1 & 0 & 0.0000 & 0.0455 & 1\\
9 & realistic & 2 & 0 & 95 & 77503142 & 2 & 1.0000 & 1 & 0.9794 & 1 & 0 & 0.0000 & 0.0206 & 1\\
10 & realistic & 1 & 0 & 124 & 77398963 & 2 & 1.0000 & 1 & 0.9920 & 1 & 0 & 0.0000 & 0.0080 & 1\\
11 & realistic & 2 & 0 & 108 & 77422535 & 2 & 1.0000 & 1 & 0.9818 & 1 & 0 & 0.0000 & 0.0182 & 1\\
14 & realistic & 6 & 0 & 150 & 77355056 & 7 & 1.0000 & 1 & 0.9615 & 1 & 0 & 0.0000 & 0.0385 & 1\\
15 & realistic & 1 & 0 & 125 & 77435743 & 9 & 1.0000 & 1 & 0.9921 & 1 & 0 & 0.0000 & 0.0079 & 1\\
18 & realistic & 4 & 0 & 123 & 77355144 & 3 & 1.0000 & 1 & 0.9685 & 1 & 0 & 0.0000 & 0.0315 & 1\\
19 & realistic & 2 & 0 & 95 & 77480228 & 6 & 1.0000 & 1 & 0.9794 & 1 & 0 & 0.0000 & 0.0206 & 1\\
\bottomrule
\end{tabular}
\end{sidewaystable}

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{{conf.perfect.hm-1}.pdf}
  \caption{Confusion matrix for observed events (below) versus expected events (right), in simulated perfect data.}
  \label{fig:conf_perfect_hm}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{{conf.realistic.hm-1}.pdf}
  \caption{Confusion matrix for observed events (below) versus expected events (right), in simulated realistic data.}
  \label{fig:conf_realistic_hm}
\end{figure}

Results on event classification are shown as heatmaps in Figures \ref{fig:conf_perfect_hm} and \ref{fig:conf_realistic_hm}, with observed events on the bottom and expected events on the side.  On the observed axis, an "unknown" event denotes a variant that could not be typed.  On the expected axis, an "unknown" event is one that does not appear in the simulation list (i.e. a false positive).  The total number of events simulated that could possibly be recovered via novel kmers is the sum of each row (except for the "unknown" row, which instead enumerates the false positives and the types they've been assigned).  For the most part, variants appear on the diagonal, indicating proper classification.  Performance degrades when we move into the non-bubble motif variants (i.e. GC and NAHR) events.

Gene conversion events are quite often erroneously described as SNPs.  This is likely due to the fact that the classification algorithm is looking for clear switches of parental copying in the child (copying from mother, then father, then mother again, or vice versa).  However, if variants that appear on different haplotypic backgrounds are too close to one another, $47$-bp kmers might span both, and the recombination motif that we seek may be obscured and cause the algorithm to call a SNP instead.

Many NAHR events are classified as "unknown".  This is perhaps not unreasonable.  Our classification algorithm for NAHR events (Algorithm \ref{alg:hasChimeras}) requires that the stretch have kmers from different chromosomes.  However, if the stretch truncates early due to errors or homology, there may be insufficient genomic context in order to determine the chromosomes of origin, leaving us unable to classify the variant accordingly.

\section{Summary}

We have presented our algorithms for identifying and typing \textit{de novo} variation in cross/pedigree data.  At the heart of our approach is a graphical model based on a de Bruijn graph representation of sequencing data from parents and children.  We exploit the novel kmer generation property of DNMs to discover regions of the graph worth exploring for DNM activity, being careful to discard kmers seemingly arising from error.  This approach appears to work well in simulation, typically recovering bubble-motif events well and exhibiting predicted difficulty with more complex, linear-motif events (those involving some form of recombination).
